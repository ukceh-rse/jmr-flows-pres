---
title:  Flow-based Generative Models
date: 2024-11-04
date-format: long
author: Joe Marsh Rossney
institute: UK Centre for Ecology & Hydrology

format:
  revealjs:
    theme: default
    slide-number: c/t
    show-slide-number: all
    footer: Lightning talk @ UKCEH Statistics Workshop, November 2024
    bibliography: references.bib
---


## A proposition

_Sometimes it is more convenient to express a complicated distribution as a complicated transformation of a simpler distribution._


![](diffusion_flower.gif){.absolute bottom=170 left=0 width=200}
![](forward.gif){.absolute bottom=140 left=650 width=400}


## Flow-based models

Learn an invertible mapping from the data to a set of variables whose joint density is trivial to sample from.

Think of them as a 'bridge' between different distributions.

![](normalizing-flow.png)

::: aside
For the statisticians: a more powerful and general form of inversion sampling.

For the mathematicians: variational families of diffeomorphisms.
:::

:::{.notes}
TODO: credit image
:::


## Flow-based models

Basic recipe for flows on $\mathbb{R}^D$:

- $q(z)$, a simple base density (e.g. a Gaussian)
- A family of invertible functions $f_\theta : \mathbb{R}^D \to \mathbb{R}^D$, parametrised by $\theta$ (weights \& biases of neural networks), with _tractable Jacobian determinant_
$$
\underbrace{p_\theta(x)}_{\text{variational density}}
= \underbrace{q\left(f_\theta^{-1}(x)\right)}_{\text{base density}}
\underbrace{\left\lvert \frac{\partial f_\theta^{-1}(x)}{\partial x} \right\rvert}_{\text{Jacobian determinant}}
$$

:::{.notes}
- Often conditioned on some context (e.g. a prompt)
- Can include stochastic steps, e.g. diffusion models
:::

## Flow-based models

- Flow-based models come with _explicit_ and _tractable_ densities.

- I.e. we don't just get the 'data' $x$, but we get the associated density $p_\theta(x)$ too.

- This is very different from other kinds of generative models, and opens up some interesting opportunities for statistics.


## One possible use-case

(Asymptotically) unbiased sampling from $p^\star$.

::::{.fragment}
:::{.callout-note icon=false}
#### Markov Chain Monte Carlo

1. Construct a stochastic process with stationary density $\pi = p^\star$
2. Thermalise
3. Sample over a period $\gg$ autocorrelation time 
:::
::::

::::{.fragment}
:::{.callout-tip icon=false}
#### Flow-based approach

1. Construct a flow-based model with variational density $p_\theta$
2. Tune $\theta$ such that $p_\theta \approx p^\star$
3. Reweight i.i.d. samples from $p_\theta$
:::
::::

:::{.notes}
I am focusing exclusively on densities that are continuous functions of the variables.
:::

## Thanks for listening


Very happy to chat if you are interested in these models, especially if

- You use MCMC and are facing scalability challenges
- You are interested in interpretable statistical emulation of process models


Get in touch: joemar@ceh.ac.uk

:::{.callout-note}
I will be giving a longer talk on the same topic in the EDS seminar on 20th November.
:::

